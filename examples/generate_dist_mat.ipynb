{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-21T10:47:35.298697600Z",
     "start_time": "2023-11-21T10:47:34.890867Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "from allib.datasets import load_uci, AVAIL_DATASETS\n",
    "from allib.metrics import distance\n",
    "from allib.utils import ensure_path\n",
    "from sklearn.metrics.pairwise import pairwise_distances, check_pairwise_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def normalize(d):\n",
    "    # normalize to 0 1\n",
    "    d = (d - d.min()) / (d.max() - d.min())\n",
    "    return d\n",
    "\n",
    "def get_dist_mat(dsn: str):\n",
    "    print(\"processing dataset \", dsn)\n",
    "    ds = load_uci(dsn)\n",
    "    ds.with_preprocess(steps=[\"sample_n\", \"continuous_to_categorical\", \"remove_constant_columns\"],  params_list=[{\"n\": 10000, \"random_state\": 0}, {\"encode\": \"ordinal\"}, {}], in_place=True)\n",
    "    data, label = ds._data, ds._label\n",
    "    cache_dir = f\"./dist_cache/{dsn}\"\n",
    "    # check if local cache is available\n",
    "    ensure_path(cache_dir)\n",
    "    nks = []\n",
    "    freq = []\n",
    "    N = data.shape[0]\n",
    "    for col in data.columns:\n",
    "        nks.append(data[col].unique().shape[0])\n",
    "        freq.append(dict(data[col].value_counts()))\n",
    "    prob = [{k: v/N for k, v in f.items()} for f in freq]\n",
    "    prob2 = [{k: (v * (v - 1))/(N * (N-1)) for k, v in f.items()} for f in freq]\n",
    "    nks = np.array(nks)\n",
    "    params = {\"prob\": prob, \"prob2\": prob2, \"nks\": nks, \"N\": N, \"freq\": freq}\n",
    "    # use tqdm to show progress\n",
    "    for dm in tqdm.tqdm(distance.AVAIL_DIST_METRICS):\n",
    "        fn = f\"{cache_dir}/{dm}_ordinal.npy\"\n",
    "        if ensure_path(fn, False):\n",
    "            continue\n",
    "        d = pairwise_distances(data, metric=distance.get_dist_metric(dm, params))\n",
    "        d = normalize(d)\n",
    "        np.save(fn, d)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T10:48:52.803175300Z",
     "start_time": "2023-11-21T10:48:52.779879500Z"
    }
   },
   "id": "1a0ba7d9633373bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing dataset  iris\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 16120.31it/s]\n",
      "D:\\anaconda3\\envs\\COMP8800\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:313: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\COMP8800\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:313: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\COMP8800\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:313: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing dataset  yeast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [24:40<00:00, 92.55s/it] \n",
      "D:\\anaconda3\\envs\\COMP8800\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:313: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\COMP8800\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:313: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\COMP8800\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:313: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 11 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\COMP8800\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:313: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 13 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\COMP8800\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:313: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 15 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing dataset  letter-recognition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 7/16 [4:36:13<9:11:23, 3675.96s/it]"
     ]
    }
   ],
   "source": [
    "for dsn in AVAIL_DATASETS:\n",
    "    if dsn == \"adult\":\n",
    "        continue\n",
    "    get_dist_mat(dsn)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-22T01:58:54.989205500Z"
    }
   },
   "id": "719de46dbeb4b7c7"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(32537, 14)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_uci(\"adult\")\n",
    "ds._data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T10:08:23.997518700Z",
     "start_time": "2023-11-21T10:08:21.175379500Z"
    }
   },
   "id": "6c32c8d5f7c40870"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "11.920928955078125"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimate file have 149*149 float\n",
    "# 149*149*4 = 88.5KB\n",
    "10000 * 10000 * 8 / 1024 / 1024 / 1024 * 16"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T10:16:15.098324600Z",
     "start_time": "2023-11-21T10:16:15.093441400Z"
    }
   },
   "id": "12c8d4ec40651d09"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
